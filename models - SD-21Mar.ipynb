{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'sugar', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n",
       "       'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n",
       "       'appet', 'pe', 'ane', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"set.csv\", na_values=['?'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column Data Type  Missing %  Unique Values           Range\n",
      "0     age   float64       2.25            NaN      2.0 - 90.0\n",
      "1      bp   float64       3.00            NaN    50.0 - 180.0\n",
      "2      sg   float64      11.75            NaN   1.005 - 1.025\n",
      "3      al   float64      11.50            NaN       0.0 - 5.0\n",
      "4   sugar   float64      12.25            NaN       0.0 - 5.0\n",
      "5     rbc    object      38.00            2.0            None\n",
      "6      pc    object      16.25            2.0            None\n",
      "7     pcc    object       1.00            2.0            None\n",
      "8      ba    object       1.00            2.0            None\n",
      "9     bgr   float64      11.00            NaN    22.0 - 490.0\n",
      "10     bu   float64       4.75            NaN     1.5 - 391.0\n",
      "11     sc   float64       4.25            NaN      0.4 - 76.0\n",
      "12    sod   float64      21.75            NaN     4.5 - 163.0\n",
      "13    pot   float64      22.00            NaN      2.5 - 47.0\n",
      "14   hemo   float64      13.00            NaN      3.1 - 17.8\n",
      "15    pcv   float64      18.00            NaN      9.0 - 54.0\n",
      "16     wc   float64      27.00            NaN  43.0 - 26400.0\n",
      "17     rc   float64      32.75            NaN    2.1 - 8400.0\n",
      "18    htn    object       1.25            5.0            None\n",
      "19     dm    object       2.00            3.0            None\n",
      "20    cad    object       1.00            2.0            None\n",
      "21  appet    object       0.25            3.0            None\n",
      "22     pe    object       0.25            3.0            None\n",
      "23    ane    object       0.25            2.0            None\n",
      "24  class    object       0.00            2.0            None\n"
     ]
    }
   ],
   "source": [
    "# Summarize the data :\n",
    "\n",
    "def summarize_dataframe(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Data Type': df.dtypes.values,\n",
    "        'Missing %': df.isnull().mean().values * 100,\n",
    "        'Unique Values': [df[col].nunique() if df[col].dtype == 'object' else None for col in df.columns],\n",
    "        'Range': [f\"{df[col].min()} - {df[col].max()}\" if df[col].dtype != 'object' else None for col in df.columns]\n",
    "    })\n",
    "\n",
    "    return summary\n",
    "\n",
    "summary = summarize_dataframe(df)\n",
    "print(summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dm']= np.where(df['dm'] == ' yes','yes',df['dm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pe\n",
       "no      311\n",
       "yes      74\n",
       "good     14\n",
       "NaN       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pe'].value_counts(dropna=False)\n",
    "# df['dm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 25)\n",
      "(400, 22)\n"
     ]
    }
   ],
   "source": [
    "# Identify Anomalous columns\n",
    "\n",
    "ANO = [\"htn\"]\n",
    "\n",
    "# Identify the columns where more than 30% observations are missing\n",
    "\n",
    "TO_DROP = [\"rbc\",\"rc\"]\n",
    "\n",
    "print(df.shape)\n",
    "df = df.drop(TO_DROP+ANO, axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Data processing on numerical fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 13), (400, 9))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split a DataFrame into two based on the data type of each column:\n",
    "\n",
    "def split_dataframe_by_dtype(df):\n",
    "    df_numeric = df.select_dtypes(include=['number'])  # Select numerical columns\n",
    "    df_categorical = df.select_dtypes(exclude=['number'])  # Select categorical (non-numeric) columns\n",
    "    return df_numeric, df_categorical\n",
    "\n",
    "df_numeric, df_categorical = split_dataframe_by_dtype(df)\n",
    "df_numeric.shape, df_categorical.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n",
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/194905897.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_numeric[col].fillna(median_value, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400, 13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to handle missing values in numerical columns + Flooring & Capping\n",
    "\n",
    "def handle_missing_and_outliers(df):\n",
    "    df_numeric = df.select_dtypes(include=['number']).copy()  # Select numerical columns\n",
    "    \n",
    "    for col in df_numeric.columns:\n",
    "        # Replace missing values with median\n",
    "        median_value = df_numeric[col].median()\n",
    "        df_numeric[col].fillna(median_value, inplace=True)\n",
    "\n",
    "        # Flooring & Capping\n",
    "        lower_bound = np.percentile(df_numeric[col], 1)  # 1st percentile\n",
    "        upper_bound = np.percentile(df_numeric[col], 99)  # 99th percentile\n",
    "        \n",
    "        df_numeric[col] = np.clip(df_numeric[col], lower_bound, upper_bound)\n",
    "\n",
    "    return df_numeric\n",
    "\n",
    "df_numeric_cleaned = handle_missing_and_outliers(df_numeric)\n",
    "df_numeric_cleaned.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing %</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0 - 80.00999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>50.0 - 110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sg</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.005 - 1.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0 - 4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sugar</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0 - 4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bgr</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>70.0 - 425.2199999999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bu</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>15.0 - 235.05999999999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sc</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5 - 18.15899999999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sod</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>113.0 - 150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pot</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2.899 - 6.5009999999999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hemo</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.798 - 17.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pcv</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>16.990000000000002 - 53.00999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wc</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3800.0 - 16721.999999999978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column Data Type  Missing % Unique Values  \\\n",
       "0     age   float64        0.0          None   \n",
       "1      bp   float64        0.0          None   \n",
       "2      sg   float64        0.0          None   \n",
       "3      al   float64        0.0          None   \n",
       "4   sugar   float64        0.0          None   \n",
       "5     bgr   float64        0.0          None   \n",
       "6      bu   float64        0.0          None   \n",
       "7      sc   float64        0.0          None   \n",
       "8     sod   float64        0.0          None   \n",
       "9     pot   float64        0.0          None   \n",
       "10   hemo   float64        0.0          None   \n",
       "11    pcv   float64        0.0          None   \n",
       "12     wc   float64        0.0          None   \n",
       "\n",
       "                                     Range  \n",
       "0                  5.0 - 80.00999999999999  \n",
       "1                             50.0 - 110.0  \n",
       "2                            1.005 - 1.025  \n",
       "3                                0.0 - 4.0  \n",
       "4                                0.0 - 4.0  \n",
       "5                 70.0 - 425.2199999999998  \n",
       "6                15.0 - 235.05999999999995  \n",
       "7                  0.5 - 18.15899999999995  \n",
       "8                            113.0 - 150.0  \n",
       "9               2.899 - 6.5009999999999994  \n",
       "10                          5.798 - 17.601  \n",
       "11  16.990000000000002 - 53.00999999999999  \n",
       "12             3800.0 - 16721.999999999978  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_numeric = summarize_dataframe(df_numeric_cleaned)\n",
    "summary_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processig on categorical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/cjnsxb116rn9py2hhzjd23gh0000gn/T/ipykernel_41385/1760110480.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_value, inplace=True)  # Replace missing values with mode\n"
     ]
    }
   ],
   "source": [
    "# Replace the missing values in categorical fileds with modal value of  the column\n",
    "\n",
    "def impute_categorical_with_mode(df):\n",
    "    for col in df.columns:\n",
    "        mode_value = df[col].mode()[0]  # Get the most frequent value\n",
    "        df[col].fillna(mode_value, inplace=True)  # Replace missing values with mode\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_categorical_imputed = impute_categorical_with_mode(df_categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pc         pcc          ba   dm cad appet   pe  ane class\n",
       "0    normal  notpresent  notpresent  yes  no  good   no   no   ckd\n",
       "1    normal  notpresent  notpresent   no  no  good   no   no   ckd\n",
       "2    normal  notpresent  notpresent  yes  no  poor   no  yes   ckd\n",
       "3  abnormal     present  notpresent   no  no  poor  yes  yes   ckd\n",
       "4    normal  notpresent  notpresent   no  no  good   no   no   ckd"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pc  pcc  ba  dm  cad appet   pe  ane  class\n",
       "0    1    0   0   1    0  good   no    0      0\n",
       "1    1    0   0   0    0  good   no    0      0\n",
       "2    1    0   0   1    0  poor   no    1      0\n",
       "3    0    1   0   0    0  poor  yes    1      0\n",
       "4    1    0   0   0    0  good   no    0      0\n",
       "5    1    0   0   1    0  good  yes    0      0\n",
       "6    1    0   0   0    0  good   no    0      0\n",
       "7    0    0   0   1    0  good  yes    0      0\n",
       "8    0    1   0   1    0  good   no    1      0\n",
       "9    0    1   0   1    0  poor   no    1      0\n",
       "10   0    1   0   1    0  good   no    1      0\n",
       "11   0    1   0   1    0  poor  yes    0      0\n",
       "12   1    1   0   1    1  poor  yes    0      0\n",
       "13   1    0   0   1    1  poor  yes    0      0\n",
       "14   0    1   1   1    1  poor  yes    0      0\n",
       "15   1    0   0   0    0  good   no    1      0\n",
       "16   1    0   0   0    0  good   no    0      0\n",
       "17   1    0   0   0    0  poor   no    0      0\n",
       "18   1    0   0   1    1  good   no    0      0\n",
       "19   0    1   0   0    1  good   no    0      0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encode categorical variables\n",
    "# LabelEncoder for 2 class\n",
    "# Onehotencoding for multiple classes\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "columns_to_encode = ['pc', 'pcc', 'ba', 'dm', 'cad', 'ane', 'class']\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    label_encoder.fit(df_categorical_imputed[col])\n",
    "    df_categorical_imputed[col] = label_encoder.transform(df_categorical_imputed[col])\n",
    "\n",
    "df_categorical_imputed.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pc  pcc  ba  dm  cad appet   pe  ane  class\n",
       "0    1    0   0   1    0  good   no    0      0\n",
       "1    1    0   0   0    0  good   no    0      0\n",
       "2    1    0   0   1    0  poor   no    1      0\n",
       "3    0    1   0   0    0  poor  yes    1      0\n",
       "4    1    0   0   0    0  good   no    0      0\n",
       "5    1    0   0   1    0  good  yes    0      0\n",
       "6    1    0   0   0    0  good   no    0      0\n",
       "7    0    0   0   1    0  good  yes    0      0\n",
       "8    0    1   0   1    0  good   no    1      0\n",
       "9    0    1   0   1    0  poor   no    1      0\n",
       "10   0    1   0   1    0  good   no    1      0\n",
       "11   0    1   0   1    0  poor  yes    0      0\n",
       "12   1    1   0   1    1  poor  yes    0      0\n",
       "13   1    0   0   1    1  poor  yes    0      0\n",
       "14   0    1   1   1    1  poor  yes    0      0\n",
       "15   1    0   0   0    0  good   no    1      0\n",
       "16   1    0   0   0    0  good   no    0      0\n",
       "17   1    0   0   0    0  poor   no    0      0\n",
       "18   1    0   0   1    1  good   no    0      0\n",
       "19   0    1   0   0    1  good   no    0      0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encode categorical variables\n",
    "# LabelEncoder for 2 class\n",
    "# Onehotencoding for multiple classes\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "columns_to_encode = ['pc', 'pcc', 'ba', 'dm', 'cad', 'ane', 'class']\n",
    "\n",
    "\n",
    "# Dictionary to hold encoders\n",
    "label_encoders = {}\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df_categorical_imputed[col])\n",
    "    df_categorical_imputed[col] = label_encoder.transform(df_categorical_imputed[col])\n",
    "    label_encoders[col] = label_encoder\n",
    "\n",
    "df_categorical_imputed.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "      <th>appet_no</th>\n",
       "      <th>appet_poor</th>\n",
       "      <th>pe_no</th>\n",
       "      <th>pe_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pc  pcc  ba  dm  cad  ane  class  appet_no  appet_poor  pe_no  pe_yes\n",
       "0    1    0   0   1    0    0      0       0.0         0.0    1.0     0.0\n",
       "1    1    0   0   0    0    0      0       0.0         0.0    1.0     0.0\n",
       "2    1    0   0   1    0    1      0       0.0         1.0    1.0     0.0\n",
       "3    0    1   0   0    0    1      0       0.0         1.0    0.0     1.0\n",
       "4    1    0   0   0    0    0      0       0.0         0.0    1.0     0.0\n",
       "5    1    0   0   1    0    0      0       0.0         0.0    0.0     1.0\n",
       "6    1    0   0   0    0    0      0       0.0         0.0    1.0     0.0\n",
       "7    0    0   0   1    0    0      0       0.0         0.0    0.0     1.0\n",
       "8    0    1   0   1    0    1      0       0.0         0.0    1.0     0.0\n",
       "9    0    1   0   1    0    1      0       0.0         1.0    1.0     0.0\n",
       "10   0    1   0   1    0    1      0       0.0         0.0    1.0     0.0\n",
       "11   0    1   0   1    0    0      0       0.0         1.0    0.0     1.0\n",
       "12   1    1   0   1    1    0      0       0.0         1.0    0.0     1.0\n",
       "13   1    0   0   1    1    0      0       0.0         1.0    0.0     1.0\n",
       "14   0    1   1   1    1    0      0       0.0         1.0    0.0     1.0\n",
       "15   1    0   0   0    0    1      0       0.0         0.0    1.0     0.0\n",
       "16   1    0   0   0    0    0      0       0.0         0.0    1.0     0.0\n",
       "17   1    0   0   0    0    0      0       0.0         1.0    1.0     0.0\n",
       "18   1    0   0   1    1    0      0       0.0         0.0    1.0     0.0\n",
       "19   0    1   0   0    1    0      0       0.0         0.0    1.0     0.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding for ['appet', 'pe']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' to avoid dummy variable trap\n",
    "\n",
    "# Select columns to encode\n",
    "columns_to_encode = ['appet', 'pe']\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "onehot_encoder.fit(df_categorical_imputed[columns_to_encode])\n",
    "encoded_array = onehot_encoder.transform(df_categorical_imputed[columns_to_encode])\n",
    "\n",
    "# Convert the encoded array to a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=onehot_encoder.get_feature_names_out(columns_to_encode))\n",
    "\n",
    "# Drop original categorical columns and concatenate the new one-hot encoded DataFrame\n",
    "df_categorical_imputed = df_categorical_imputed.drop(columns_to_encode, axis=1)\n",
    "df_categorical_imputed = pd.concat([df_categorical_imputed, encoded_df], axis=1)\n",
    "\n",
    "df_categorical_imputed.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for column: pc\n",
      "pc\n",
      "1    324\n",
      "0     76\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: pcc\n",
      "pcc\n",
      "0    358\n",
      "1     42\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: ba\n",
      "ba\n",
      "0    378\n",
      "1     22\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: dm\n",
      "dm\n",
      "0    267\n",
      "1    133\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: cad\n",
      "cad\n",
      "0    360\n",
      "1     40\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: ane\n",
      "ane\n",
      "0    338\n",
      "1     62\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: class\n",
      "class\n",
      "0    250\n",
      "1    150\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: appet_no\n",
      "appet_no\n",
      "0.0    386\n",
      "1.0     14\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: appet_poor\n",
      "appet_poor\n",
      "0.0    318\n",
      "1.0     82\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: pe_no\n",
      "pe_no\n",
      "1.0    312\n",
      "0.0     88\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Value counts for column: pe_yes\n",
      "pe_yes\n",
      "0.0    326\n",
      "1.0     74\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for col in df_categorical_imputed.columns:\n",
    "    print(f\"Value counts for column: {col}\")\n",
    "    print(df_categorical_imputed[col].value_counts(dropna=False))\n",
    "    print(\"-\" * 40)  # Separator for better readability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine numeric & categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 22)\n",
      "(400, 24)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df_cleaned = pd.concat([df_numeric_cleaned,df_categorical_imputed], axis =1)\n",
    "print(df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing %</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0 - 80.00999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>50.0 - 110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sg</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.005 - 1.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0 - 4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sugar</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0 - 4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bgr</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>70.0 - 425.2199999999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bu</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>15.0 - 235.05999999999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sc</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5 - 18.15899999999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sod</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>113.0 - 150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pot</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2.899 - 6.5009999999999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hemo</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.798 - 17.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pcv</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>16.990000000000002 - 53.00999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wc</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3800.0 - 16721.999999999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pc</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0 - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pcc</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0 - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ba</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0 - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dm</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0 - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cad</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0 - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ane</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0 - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>class</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0 - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>appet_no</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>appet_poor</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pe_no</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pe_yes</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0 - 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Column Data Type  Missing % Unique Values  \\\n",
       "0          age   float64        0.0          None   \n",
       "1           bp   float64        0.0          None   \n",
       "2           sg   float64        0.0          None   \n",
       "3           al   float64        0.0          None   \n",
       "4        sugar   float64        0.0          None   \n",
       "5          bgr   float64        0.0          None   \n",
       "6           bu   float64        0.0          None   \n",
       "7           sc   float64        0.0          None   \n",
       "8          sod   float64        0.0          None   \n",
       "9          pot   float64        0.0          None   \n",
       "10        hemo   float64        0.0          None   \n",
       "11         pcv   float64        0.0          None   \n",
       "12          wc   float64        0.0          None   \n",
       "13          pc     int64        0.0          None   \n",
       "14         pcc     int64        0.0          None   \n",
       "15          ba     int64        0.0          None   \n",
       "16          dm     int64        0.0          None   \n",
       "17         cad     int64        0.0          None   \n",
       "18         ane     int64        0.0          None   \n",
       "19       class     int64        0.0          None   \n",
       "20    appet_no   float64        0.0          None   \n",
       "21  appet_poor   float64        0.0          None   \n",
       "22       pe_no   float64        0.0          None   \n",
       "23      pe_yes   float64        0.0          None   \n",
       "\n",
       "                                     Range  \n",
       "0                  5.0 - 80.00999999999999  \n",
       "1                             50.0 - 110.0  \n",
       "2                            1.005 - 1.025  \n",
       "3                                0.0 - 4.0  \n",
       "4                                0.0 - 4.0  \n",
       "5                 70.0 - 425.2199999999998  \n",
       "6                15.0 - 235.05999999999995  \n",
       "7                  0.5 - 18.15899999999995  \n",
       "8                            113.0 - 150.0  \n",
       "9               2.899 - 6.5009999999999994  \n",
       "10                          5.798 - 17.601  \n",
       "11  16.990000000000002 - 53.00999999999999  \n",
       "12             3800.0 - 16721.999999999978  \n",
       "13                                   0 - 1  \n",
       "14                                   0 - 1  \n",
       "15                                   0 - 1  \n",
       "16                                   0 - 1  \n",
       "17                                   0 - 1  \n",
       "18                                   0 - 1  \n",
       "19                                   0 - 1  \n",
       "20                               0.0 - 1.0  \n",
       "21                               0.0 - 1.0  \n",
       "22                               0.0 - 1.0  \n",
       "23                               0.0 - 1.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_dataframe(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - Training & testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DiVide the dataset into indepent and dependent features\n",
    "X=df_cleaned.drop('class',axis=1)\n",
    "y=df_cleaned['class']\n",
    "\n",
    "## Split the data in training and tetsing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  \n",
    "\n",
    "\n",
    "## Scale these features\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21271572,  1.94906988, -0.51825415, ..., -0.51298918,\n",
       "         0.51946248, -0.46056619],\n",
       "       [ 0.9652051 ,  0.34434682, -1.43282029, ...,  1.94935887,\n",
       "        -1.92506684,  2.17124059],\n",
       "       [-1.58168202,  0.34434682, -0.51825415, ..., -0.51298918,\n",
       "        -1.92506684,  2.17124059],\n",
       "       ...,\n",
       "       [-0.36612226, -0.4580147 , -1.43282029, ..., -0.51298918,\n",
       "        -1.92506684,  2.17124059],\n",
       "       [ 0.32848332,  0.34434682,  0.39631199, ..., -0.51298918,\n",
       "         0.51946248, -0.46056619],\n",
       "       [ 0.79155371, -1.26037623, -1.43282029, ...,  1.94935887,\n",
       "         0.51946248, -0.46056619]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'sugar', 'bgr', 'bu', 'sc', 'sod', 'pot',\n",
       "       'hemo', 'pcv', 'wc', 'pc', 'pcc', 'ba', 'dm', 'cad', 'ane', 'class',\n",
       "       'appet_no', 'appet_poor', 'pe_no', 'pe_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikeras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING-ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8170 - loss: 0.4401 - val_accuracy: 0.9875 - val_loss: 0.0628\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9870 - loss: 0.0619 - val_accuracy: 0.9875 - val_loss: 0.0240\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9953 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9953 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.8877e-04 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 6.0225e-04 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.9536e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 4.1822e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.6164e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.1950e-04 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.8488e-04 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.5602e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.3060e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.1046e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.9298e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.7747e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.6372e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.5145e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.4024e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.3031e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.2112e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.1313e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.0574e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.9184e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.3174e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 8.7804e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.3241e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 7.8716e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 7.4624e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 7.0858e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.7483e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.4254e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.1244e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.8491e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.5883e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.3518e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.1274e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.9190e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.7153e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.5296e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.3547e-05 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.1957e-05 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.0357e-05 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.8899e-05 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.7488e-05 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.6221e-05 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.4956e-05 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9477 - loss: 0.2518\n",
      "Final Validation Accuracy: 1.0\n",
      "Test Accuracy: 0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import datetime\n",
    "\n",
    "# Set global random seed for reproducibility\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Build ANN Model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # HL1\n",
    "    Dense(32, activation='relu'),  # HL2\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set up TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Set up Early Stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[tensorflow_callback, early_stopping_callback]\n",
    ")\n",
    "\n",
    "# Get final validation accuracy\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Final Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0000\n",
      "Test Accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "## Predict on validation and test sets\n",
    "y_val_pred = rf_model.predict(X_val)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "## Calculate accuracy\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "## Print the accuracies\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9875\n",
      "Test Accuracy: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:25:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=50, max_depth=3, min_child_weight=3, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Validate model\n",
    "y_valid_pred = xgb_model.predict(X_val)\n",
    "valid_accuracy = accuracy_score(y_val, y_valid_pred)\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "\n",
    "# Test model\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0000\n",
      "Test Accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize CatBoost Classifier\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=100,        # Number of boosting rounds\n",
    "    learning_rate=0.1,     # Step size\n",
    "    depth=6,              # Maximum depth of trees\n",
    "    random_seed=42,\n",
    "    verbose=0,            # Suppresses training logs\n",
    "    eval_metric='Accuracy'\n",
    ")\n",
    "\n",
    "# Train model\n",
    "cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10, verbose=0)\n",
    "\n",
    "# Validate model\n",
    "y_valid_pred = cat_model.predict(X_val)\n",
    "valid_accuracy = accuracy_score(y_val, y_valid_pred)\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "\n",
    "# Test model\n",
    "y_test_pred = cat_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade scikit-learn scikeras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# import tensorflow as tf\n",
    "# import scikeras\n",
    "\n",
    "# print(\"Scikit-Learn:\", sklearn.__version__)\n",
    "# print(\"TensorFlow:\", tf.__version__)\n",
    "# print(\"SciKeras:\", scikeras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Ensemble Accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:25:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_nn_model():\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)), \n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap NN model using KerasClassifier\n",
    "nn_model = KerasClassifier(model=create_nn_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Train the NN model separately\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Get NN predictions (convert probabilities to class labels)\n",
    "nn_preds = (nn_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train Voting Classifier (excluding NN)\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('cat', cat_model)\n",
    "    ],\n",
    "    voting='hard'  # Majority voting\n",
    ")\n",
    "\n",
    "# Train ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Get ensemble predictions\n",
    "ensemble_preds = ensemble_model.predict(X_test)\n",
    "\n",
    "final_preds = ((ensemble_preds + nn_preds.flatten()) / 2 >= 0.3).astype(int)\n",
    "\n",
    "# Accuracy Calculation\n",
    "ensemble_accuracy = accuracy_score(y_test, final_preds)\n",
    "print(f'Final Ensemble Accuracy: {ensemble_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predictions saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the final predictions\n",
    "with open('final_preds.pkl', 'wb') as f:\n",
    "    pickle.dump(final_preds, f)\n",
    "\n",
    "print(\"Final predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model Trasformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle dump StandardScaler()\n",
    "\n",
    "with open('scaler_SD.pkl','wb') as file:\n",
    "    pickle.dump(scaler,file)\n",
    "\n",
    "\n",
    "# Pickle dump label encoder,Onehot encoder\n",
    "\n",
    "# with open('label_encoder_SD.pkl','wb') as file:\n",
    "#     pickle.dump(label_encoder,file)\n",
    "\n",
    "with open('onehot_encoder_SD.pkl','wb') as file:\n",
    "    pickle.dump(onehot_encoder,file)\n",
    "\n",
    "with open('label_encoder_SD.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoders, file)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Train the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "with open('models/random_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:25:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "# Train the model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "with open('models/xgboost.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "\n",
    "# Train the model\n",
    "cat_model = CatBoostClassifier(verbose=0)\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "with open('models/catboost.pkl', 'wb') as f:\n",
    "    pickle.dump(cat_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5858 - loss: 0.6802 - val_accuracy: 0.8625 - val_loss: 0.5307\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9029 - loss: 0.5053 - val_accuracy: 0.9625 - val_loss: 0.4011\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9665 - loss: 0.3881 - val_accuracy: 0.9750 - val_loss: 0.3139\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9737 - loss: 0.3031 - val_accuracy: 0.9750 - val_loss: 0.2534\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9751 - loss: 0.2398 - val_accuracy: 0.9750 - val_loss: 0.2103\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9798 - loss: 0.1922 - val_accuracy: 0.9750 - val_loss: 0.1802\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9808 - loss: 0.1559 - val_accuracy: 0.9750 - val_loss: 0.1593\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9828 - loss: 0.1277 - val_accuracy: 0.9750 - val_loss: 0.1448\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9890 - loss: 0.1055 - val_accuracy: 0.9750 - val_loss: 0.1344\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9917 - loss: 0.0878 - val_accuracy: 0.9750 - val_loss: 0.1266\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pickle\n",
    "\n",
    "# Build and compile the ANN model\n",
    "ann_model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "with open('models/ann.pkl', 'wb') as f:\n",
    "    pickle.dump(ann_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.1.3 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.1.3 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.1.3 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load transformer from the file\n",
    "with open('models/data_transformation.pkl', 'rb') as file:\n",
    "    transformer = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for 'cat': [array(['abnormal', 'normal', nan], dtype=object), array(['abnormal', 'normal', nan], dtype=object), array(['notpresent', 'present', nan], dtype=object), array(['notpresent', 'present', nan], dtype=object), array(['4', '5.2', '8', 'no', 'yes', nan], dtype=object), array(['no', 'yes', nan], dtype=object), array(['no', 'yes', nan], dtype=object), array(['good', 'no', 'poor', nan], dtype=object), array(['good', 'no', 'yes', nan], dtype=object), array(['no', 'yes', nan], dtype=object), array(['ckd', 'notckd'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "if hasattr(transformer, 'named_transformers_'):\n",
    "    for name, transformer_obj in transformer.named_transformers_.items():\n",
    "        if hasattr(transformer_obj, 'categories_'):\n",
    "            print(f\"Categories for '{name}': {transformer_obj.categories_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  bp     sg  al  su  rbc  pc  pcc  ba  bgr  bu   sc  sod\n",
      "0   50  80  1.015   0   0    1   1    1   1  100  30  1.2  135\n",
      "Transformation Error: columns are missing: {'sugar', 'rc', 'class', 'htn', 'hemo', 'dm', 'pot', 'cad', 'appet', 'pcv', 'pe', 'wc', 'ane'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example input dictionary (adjust according to your actual input fields)\n",
    "data = {\n",
    "    'age': 50,\n",
    "    'bp': 80,\n",
    "    'sg': 1.015,\n",
    "    'al': 0,\n",
    "    'su': 0,\n",
    "    'rbc': 1,\n",
    "    'pc': 1,\n",
    "    'pcc': 1,\n",
    "    'ba': 1,\n",
    "    'bgr': 100,\n",
    "    'bu': 30,\n",
    "    'sc': 1.2,\n",
    "    'sod': 135\n",
    "}\n",
    "\n",
    "# Create DataFrame from input\n",
    "input_df = pd.DataFrame([data])\n",
    "print(input_df)\n",
    "try:\n",
    "    input_scaled = transformer.transform(input_df)\n",
    "    print(\"Input data transformed successfully!\")\n",
    "except ValueError as e:\n",
    "    print(f\"Transformation Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:25:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ensemble model saved as 'ensemble_model.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate a synthetic dataset (Replace this with actual CKD dataset)\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "catboost = CatBoostClassifier(verbose=0, random_state=42)\n",
    "ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "# Create Ensemble Model using Voting Classifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('catboost', catboost), ('ann', ann)],\n",
    "    voting='hard'  # 'hard' for majority voting, 'soft' for probability-based voting\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained ensemble model\n",
    "with open(\"ensemble_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(ensemble_model, file)\n",
    "\n",
    "print(\"✅ Ensemble model saved as 'ensemble_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Columns: ['age' 'bp' 'sg' 'al' 'sugar' 'rbc' 'pc' 'pcc' 'ba' 'bgr' 'bu' 'sc' 'sod'\n",
      " 'pot' 'hemo' 'pcv' 'wc' 'rc' 'htn' 'dm' 'cad' 'appet' 'pe' 'ane' 'class']\n"
     ]
    }
   ],
   "source": [
    "expected_columns = transformer.feature_names_in_\n",
    "print(\"Expected Columns:\", expected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame Columns: Index(['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n",
      "       'sc', 'sod'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Input DataFrame Columns:\", input_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in expected_columns:\n",
    "    if col not in input_df.columns:\n",
    "        input_df[col] = np.nan  # or some default value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.rename(columns={'su': 'sugar'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'class' in input_df.columns:\n",
    "    input_df.drop(columns=['class'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns are missing: {'class'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(input_df)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1090\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     diff \u001b[38;5;241m=\u001b[39m all_names \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(column_names)\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m-> 1090\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     _check_n_features(\u001b[38;5;28mself\u001b[39m, X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: columns are missing: {'class'}"
     ]
    }
   ],
   "source": [
    "transformed_data = transformer.transform(input_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
